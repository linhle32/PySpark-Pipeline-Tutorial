{"paragraphs":[{"text":"%md\n\n# PySpark Processing Pipeline \n\nThis notebook aims to explain major steps in a data processing pipeline. Therefore, most the steps come with some code to check their results (mostly `printSchema()` and `show()`. For an end-to-end pipeline, please use the `pipeline_template` notebook.\n\n### Loading Data\n\nChange the csv path to your correct file which should be stored in a HDFS cluster.\n\n`printSchema()` will display the columns' names and types","user":"anonymous","dateUpdated":"2023-01-25T00:59:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>PySpark Processing Pipeline</h1>\n<p>This notebook aims to explain major steps in a data processing pipeline. Therefore, most the steps come with some code to check their results (mostly <code>printSchema()</code> and <code>show()</code>. For an end-to-end pipeline, please use the <code>pipeline_template</code> notebook.</p>\n<h3>Loading Data</h3>\n<p>Change the csv path to your correct file which should be stored in a HDFS cluster.</p>\n<p><code>printSchema()</code> will display the columns' names and types</p>\n"}]},"apps":[],"jobName":"paragraph_1674568940156_1074212990","id":"20230124-200721_1933496500","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:59:48+0000","dateFinished":"2023-01-25T00:59:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:10654"},{"text":"%spark2.pyspark\n\n#path to data\nhdfs_path = '/tmp/data/'\ndata_file = 'heart_disease.csv'\n\ndata = spark.read.options(header='True',inferSchema='True',delimiter=',').csv(\"/tmp/data/heart_disease.csv\")\ndata.printSchema()","user":"anonymous","dateUpdated":"2023-01-25T00:32:16+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Age: integer (nullable = true)\n |-- Sex: string (nullable = true)\n |-- ChestPainType: string (nullable = true)\n |-- RestingBP: integer (nullable = true)\n |-- Cholesterol: integer (nullable = true)\n |-- FastingBS: integer (nullable = true)\n |-- RestingECG: string (nullable = true)\n |-- MaxHR: integer (nullable = true)\n |-- ExerciseAngina: string (nullable = true)\n |-- Oldpeak: double (nullable = true)\n |-- ST_Slope: string (nullable = true)\n |-- HeartDisease: integer (nullable = true)\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=0","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=1"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940194_-514219966","id":"20230124-141029_1046446419","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:32:16+0000","dateFinished":"2023-01-25T00:32:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10655"},{"text":"%md\n\nCheck some rows with `show()`\n","user":"anonymous","dateUpdated":"2023-01-25T00:13:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Check some rows with <code>show()</code></p>\n"}]},"apps":[],"jobName":"paragraph_1674605566452_-1512966911","id":"20230125-001246_233279246","dateCreated":"2023-01-25T00:12:46+0000","dateStarted":"2023-01-25T00:13:18+0000","dateFinished":"2023-01-25T00:13:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10656"},{"text":"%spark2.pyspark\ndata.show()","user":"anonymous","dateUpdated":"2023-01-25T00:32:38+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|\n+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n| 40|  M|          ATA|      140|        289|        0|    Normal|  172|             N|    0.0|      Up|           0|\n| 49|  F|          NAP|      160|        180|        0|    Normal|  156|             N|    1.0|    Flat|           1|\n| 37|  M|          ATA|      130|        283|        0|        ST|   98|             N|    0.0|      Up|           0|\n| 48|  F|          ASY|      138|        214|        0|    Normal|  108|             Y|    1.5|    Flat|           1|\n| 54|  M|          NAP|      150|        195|        0|    Normal|  122|             N|    0.0|      Up|           0|\n| 39|  M|          NAP|      120|        339|        0|    Normal|  170|             N|    0.0|      Up|           0|\n| 45|  F|          ATA|      130|        237|        0|    Normal|  170|             N|    0.0|      Up|           0|\n| 54|  M|          ATA|      110|        208|        0|    Normal|  142|             N|    0.0|      Up|           0|\n| 37|  M|          ASY|      140|        207|        0|    Normal|  130|             Y|    1.5|    Flat|           1|\n| 48|  F|          ATA|      120|        284|        0|    Normal|  120|             N|    0.0|      Up|           0|\n| 37|  F|          NAP|      130|        211|        0|    Normal|  142|             N|    0.0|      Up|           0|\n| 58|  M|          ATA|      136|        164|        0|        ST|   99|             Y|    2.0|    Flat|           1|\n| 39|  M|          ATA|      120|        204|        0|    Normal|  145|             N|    0.0|      Up|           0|\n| 49|  M|          ASY|      140|        234|        0|    Normal|  140|             Y|    1.0|    Flat|           1|\n| 42|  F|          NAP|      115|        211|        0|        ST|  137|             N|    0.0|      Up|           0|\n| 54|  F|          ATA|      120|        273|        0|    Normal|  150|             N|    1.5|    Flat|           0|\n| 38|  M|          ASY|      110|        196|        0|    Normal|  166|             N|    0.0|    Flat|           1|\n| 43|  F|          ATA|      120|        201|        0|    Normal|  165|             N|    0.0|      Up|           0|\n| 60|  M|          ASY|      100|        248|        0|    Normal|  125|             N|    1.0|    Flat|           1|\n| 36|  M|          ATA|      120|        267|        0|    Normal|  160|             N|    3.0|    Flat|           1|\n+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=2"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940195_1736878643","id":"20230124-152742_1484821132","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:32:38+0000","dateFinished":"2023-01-25T00:32:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10657"},{"text":"%md\n\n#### Change all integer columns to float\n\nWe need to change all integer columns to float types, otherwise, we will get errors in modeling.\n\nModify the code below to include all integer columns in `integer_cols` (as strings). `printSchema()` then verifies if everything is double. In my example, `PatientID` is not casted since we will drop it anyway.","user":"anonymous","dateUpdated":"2023-01-25T00:29:47+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Change all integer columns to float</h4>\n<p>We need to change all integer columns to float types, otherwise, we will get errors in modeling.</p>\n<p>Modify the code below to include all integer columns in <code>integer_cols</code> (as strings). <code>printSchema()</code> then verifies if everything is double. In my example, <code>PatientID</code> is not casted since we will drop it anyway.</p>\n"}]},"apps":[],"jobName":"paragraph_1674568940195_1643253473","id":"20230124-201636_816637435","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:29:47+0000","dateFinished":"2023-01-25T00:29:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10658"},{"text":"%spark2.pyspark\n\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import DoubleType\n\ninteger_cols = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'HeartDisease']\n\nfor c in integer_cols:\n    data = data.withColumn(c, col(c).cast(DoubleType()))\n\ndata.printSchema()","user":"anonymous","dateUpdated":"2023-01-25T00:32:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Age: double (nullable = true)\n |-- Sex: string (nullable = true)\n |-- ChestPainType: string (nullable = true)\n |-- RestingBP: double (nullable = true)\n |-- Cholesterol: double (nullable = true)\n |-- FastingBS: double (nullable = true)\n |-- RestingECG: string (nullable = true)\n |-- MaxHR: double (nullable = true)\n |-- ExerciseAngina: string (nullable = true)\n |-- Oldpeak: double (nullable = true)\n |-- ST_Slope: string (nullable = true)\n |-- HeartDisease: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1674568940195_-146816803","id":"20230124-165845_1320819949","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:32:46+0000","dateFinished":"2023-01-25T00:32:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10659"},{"text":"%md\n\n#### Drop unnecessary columns\n\nDrop all unneccessary columns in the paragraph below by including them in the `drop_cols` list. Verify with the result of `printSchema()`. \n\nIn general, ID columns and name columns (first name, last name, middle name, etc) should be dropped.","user":"anonymous","dateUpdated":"2023-01-25T00:29:52+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Drop unnecessary columns</h4>\n<p>Drop all unneccessary columns in the paragraph below by including them in the <code>drop_cols</code> list. Verify with the result of <code>printSchema()</code>.</p>\n<p>In general, ID columns and name columns (first name, last name, middle name, etc) should be dropped.</p>\n"}]},"apps":[],"jobName":"paragraph_1674568940196_1208162841","id":"20230124-201821_1344680715","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:29:52+0000","dateFinished":"2023-01-25T00:29:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10660"},{"text":"%spark2.pyspark\n\ndrop_cols = ['PatientID']\ndata_main = data.drop(*drop_cols)\ndata_main.printSchema()","user":"anonymous","dateUpdated":"2023-01-25T00:32:49+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Age: double (nullable = true)\n |-- Sex: string (nullable = true)\n |-- ChestPainType: string (nullable = true)\n |-- RestingBP: double (nullable = true)\n |-- Cholesterol: double (nullable = true)\n |-- FastingBS: double (nullable = true)\n |-- RestingECG: string (nullable = true)\n |-- MaxHR: double (nullable = true)\n |-- ExerciseAngina: string (nullable = true)\n |-- Oldpeak: double (nullable = true)\n |-- ST_Slope: string (nullable = true)\n |-- HeartDisease: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1674568940196_-1385278208","id":"20230124-152535_1737355475","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:32:49+0000","dateFinished":"2023-01-25T00:32:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10661"},{"text":"%md\n\n### Train Test Splitting\n\nChange the 0.7 - 0.3 ratio to other as needed. Then, we use `count()` to verify the sizes of the two sets","user":"anonymous","dateUpdated":"2023-01-25T00:26:56+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Train Test Splitting</h3>\n<p>Change the 0.7 - 0.3 ratio to other as needed. Then, we use <code>count()</code> to verify the sizes of the two sets</p>\n"}]},"apps":[],"jobName":"paragraph_1674568940196_348779068","id":"20230124-202223_283821740","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:26:56+0000","dateFinished":"2023-01-25T00:26:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10662"},{"text":"%spark2.pyspark\n\ndata_train, data_test = data_main.randomSplit([0.7, 0.3])\n\ndata_train.count(), data_test.count()","user":"anonymous","dateUpdated":"2023-01-25T00:32:54+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(651, 267)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=3","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=4"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940197_-1157618445","id":"20230124-152710_324354579","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:32:55+0000","dateFinished":"2023-01-25T00:33:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10663"},{"text":"%md\n\n### Processing Pipeline\n\nModify `string_cols`, `numeric_cols`, and `target` to include the correct columns in each list. The pipeline below will\n- Index all string columns (categorical columns) then perform one hot encoder. Missing is dealed with by `handleInvalid='keep'`\n- Impute all numeric columns, then standardize them\n- Assemble all processed columns in a Vector `features`","user":"anonymous","dateUpdated":"2023-01-25T01:01:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Processing Pipeline</h3>\n<p>Modify <code>string_cols</code>, <code>numeric_cols</code>, and <code>target</code> to include the correct columns in each list. The pipeline below will</p>\n<ul>\n<li>Index all string columns (categorical columns) then perform one hot encoder. Missing is dealed with by <code>handleInvalid='keep'</code></li>\n<li>Impute all numeric columns, then standardize them</li>\n<li>Assemble all processed columns in a Vector <code>features</code></li>\n</ul>\n"}]},"apps":[],"jobName":"paragraph_1674568940197_1957455405","id":"20230124-205038_993821482","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T01:01:43+0000","dateFinished":"2023-01-25T01:01:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10664"},{"text":"%spark2.pyspark\nstring_cols = ['ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\nnumeric_cols = ['Age','RestingBP','Cholesterol','FastingBS','MaxHR','Oldpeak']\ntarget = 'HeartDisease'\n\n\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, Imputer, StandardScaler, VectorAssembler\nfrom pyspark.ml import Pipeline\n\n###one hot encode the categorical columns\nencoders = []\nfor c in string_cols:\n    encoders.append(StringIndexer(inputCol=c, outputCol=c+'Index', handleInvalid='keep'))\n    encoders.append(OneHotEncoder(inputCol=c+'Index', outputCol=c+'Codes'))\n\n###impute the numeric columns\nimputer = Imputer(inputCols = numeric_cols, outputCols = [c+'Imp' for c in numeric_cols], strategy = 'median')\n\n###standardization\nnum_assembler = VectorAssembler(inputCols=[c+'Imp' for c in numeric_cols], outputCol='imputed')\nscaler = StandardScaler(inputCol = 'imputed', outputCol = 'scaled')\n\n###combine results\nassembler = VectorAssembler(inputCols=[c+'Codes' for c in string_cols]+['scaled'], outputCol='features')\n\n\n\n###build pipeline\npipeline = Pipeline(stages = encoders + [imputer, num_assembler, scaler, assembler])\n\n###train pipeline\npipeline_trained = pipeline.fit(data_train)","user":"anonymous","dateUpdated":"2023-01-25T00:50:19+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=12","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=13","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=14","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=15","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=16","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=17","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=18","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=19"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940197_-1565882494","id":"20230124-171508_406577413","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:50:21+0000","dateFinished":"2023-01-25T00:50:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10665"},{"text":"%md\n\n#### Transform the training data with the pipeline","user":"anonymous","dateUpdated":"2023-01-25T00:28:51+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Transform the training data with the pipeline</h4>\n"}]},"apps":[],"jobName":"paragraph_1674606511267_72050476","id":"20230125-002831_1453010561","dateCreated":"2023-01-25T00:28:31+0000","dateStarted":"2023-01-25T00:28:51+0000","dateFinished":"2023-01-25T00:28:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10666"},{"text":"%spark2.pyspark\n\ntrain_prc = pipeline_trained.transform(data_train).select(target,'features')\ntrain_prc.show()","user":"anonymous","dateUpdated":"2023-01-25T00:50:48+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+--------------------+\n|HeartDisease|            features|\n+------------+--------------------+\n|         0.0|(18,[2,6,7,10,12,...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[2,6,7,10,12,...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[3,5,7,10,12,...|\n|         0.0|(18,[2,5,7,10,12,...|\n|         1.0|(18,[0,4,8,9,12,1...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         1.0|(18,[0,4,7,9,12,1...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         1.0|(18,[3,4,7,10,12,...|\n|         1.0|(18,[0,4,8,9,12,1...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         1.0|(18,[0,4,7,10,12,...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[2,5,7,10,12,...|\n|         1.0|(18,[3,4,7,9,12,1...|\n|         0.0|(18,[0,4,7,10,12,...|\n|         0.0|(18,[3,5,7,10,12,...|\n|         1.0|(18,[0,4,8,9,12,1...|\n+------------+--------------------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=20","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=21","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=22","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=23"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940197_-1861275465","id":"20230124-175256_1002768516","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:50:49+0000","dateFinished":"2023-01-25T00:50:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10667"},{"text":"%md\n\n#### Transform the testing data with the pipeline","user":"anonymous","dateUpdated":"2023-01-25T00:28:59+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Transform the testing data with the pipeline</h4>\n"}]},"apps":[],"jobName":"paragraph_1674606534753_992806146","id":"20230125-002854_1360253368","dateCreated":"2023-01-25T00:28:54+0000","dateStarted":"2023-01-25T00:28:59+0000","dateFinished":"2023-01-25T00:29:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10668"},{"text":"%spark2.pyspark\n\ntest_prc = pipeline_trained.transform(data_test).select(target,'features')\ntest_prc.show()","user":"anonymous","dateUpdated":"2023-01-25T00:51:03+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+--------------------+\n|HeartDisease|            features|\n+------------+--------------------+\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[1,4,7,10,12,...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[3,6,7,10,12,...|\n|         0.0|(18,[0,4,7,10,12,...|\n|         1.0|(18,[0,4,8,9,12,1...|\n|         1.0|(18,[0,6,8,10,12,...|\n|         0.0|(18,[2,6,7,10,12,...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[1,4,7,9,12,1...|\n|         1.0|(18,[0,4,8,9,12,1...|\n|         0.0|(18,[2,5,7,10,12,...|\n|         0.0|(18,[1,4,7,11,12,...|\n|         1.0|(18,[0,4,7,10,12,...|\n|         1.0|(18,[0,4,8,9,12,1...|\n|         1.0|(18,[0,4,7,9,12,1...|\n|         1.0|(18,[0,4,8,11,12,...|\n|         0.0|(18,[2,4,7,10,12,...|\n|         0.0|(18,[1,4,7,10,12,...|\n+------------+--------------------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=24","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=25","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=26","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=27"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940198_-2055810235","id":"20230124-180620_157977192","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:51:03+0000","dateFinished":"2023-01-25T00:51:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10669"},{"text":"%md\n\n## Modeling\n\nTraining a simple model and check its performance. This part is just for demonstration.","user":"anonymous","dateUpdated":"2023-01-25T00:29:24+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Modeling</h2>\n<p>Training a simple model and check its performance. This part is just for demonstration.</p>\n"}]},"apps":[],"jobName":"paragraph_1674568940198_1413713681","id":"20230124-211226_580908956","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:29:24+0000","dateFinished":"2023-01-25T00:29:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10670"},{"text":"%spark2.pyspark\n\nfrom pyspark.ml.classification import LogisticRegression\n\nlogistic_model = LogisticRegression(featuresCol='features', labelCol=target)\n\nlogistic_trained = logistic_model.fit(train_prc)","user":"anonymous","dateUpdated":"2023-01-25T00:51:22+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=28","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=29","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=30","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=31","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=32","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=33","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=34","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=35","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=36","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=37","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=38","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=39","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=40","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=41","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=42","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=43","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=44","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=45","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=46","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=47","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=48","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=49","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=50","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=51","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=52","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=53","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=54","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=55","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=56","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=57","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=58","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=59","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=60","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=61","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=62","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=63","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=64"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940199_-462498730","id":"20230124-181125_1302286594","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:51:22+0000","dateFinished":"2023-01-25T00:51:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10671"},{"text":"%spark2.pyspark\ntrain_predicted = logistic_trained.transform(train_prc)\ntrain_predicted.crosstab(target, 'prediction').show()","user":"anonymous","dateUpdated":"2023-01-25T00:51:56+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------------+---+---+\n|HeartDisease_prediction|0.0|1.0|\n+-----------------------+---+---+\n|                    1.0| 42|321|\n|                    0.0|241| 47|\n+-----------------------+---+---+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=65","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=66","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=67","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=68","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=69"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940199_-1104188882","id":"20230124-184539_1694421190","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:51:57+0000","dateFinished":"2023-01-25T00:52:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10672"},{"text":"%spark2.pyspark\ntest_predicted = logistic_trained.transform(test_prc)\ntest_predicted.crosstab(target, 'prediction').show()","user":"anonymous","dateUpdated":"2023-01-25T00:52:01+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------------------+---+---+\n|HeartDisease_prediction|0.0|1.0|\n+-----------------------+---+---+\n|                    1.0| 20|125|\n|                    0.0|100| 22|\n+-----------------------+---+---+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=70","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=71","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=72","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=73","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=74"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1674568940200_544336922","id":"20230124-184404_527645336","dateCreated":"2023-01-24T14:02:20+0000","dateStarted":"2023-01-25T00:52:03+0000","dateFinished":"2023-01-25T00:52:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:10673"},{"text":"%spark2.pyspark\n","user":"anonymous","dateUpdated":"2023-01-25T00:52:01+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1674607921188_998014907","id":"20230125-005201_1902314815","dateCreated":"2023-01-25T00:52:01+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:10674"}],"name":"pipeline_explain","id":"2HRN3KGVS","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}